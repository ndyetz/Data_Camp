---
title: "Working with Dates and Times in R"
subtitle: Lessons from DataCamp
output:
  html_notebook:
    toc: yes
    toc_float: true
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_float: true
---

#Introduction

The following documentoutlines the written portion of the lessons from [DataCamp](https://www.datacamp.com/)'s [Working with Dates and Times in R](https://www.datacamp.com/courses/working-with-dates-and-times-in-r). This requires intermediate knowledge with R and an understanding of Data manipulations with dplyr. 

As a note: All text is completely copied and pasted from the course. There are insances where the document refers to the "editor on the right", please note, that in this notebook document all of the instances are noted in the "r-chunks" (areas containing working r-code), which occurs below the text, rather than to the right. Furthermore, This lesson contained instructional videos at the beginign of new concepts that are not detailed in this document. However, even without these videos, the instructions are quite clear in indicating what the code is accomplishing. 

<u>*If you have this document open on "R-Notebook", simply click "run" -> "Run all" (Or just press 'ctrl + alt + r'), let the "r-chunks" run (This might take a bit of time) then click "Preview". All necessary data is embedded within the code, no need to set a working directory or open an R-project.*</u>

This document was created by Neil Yetz on 09/23/2018. Please send any questions or concerns in this document to Neil at <ndyetz@gmail.com>



<center>
![](http://www.learndatasci.com/wp-content/uploads/2015/10/DataCamp50h1.png)  
</center>

\newpage


#Clear environment
```{r}
rm(list=ls())
```



#Load Libraries
```{r, message = FALSE, warning = FALSE}
library(readr)
library(anytime)
library(ggplot2)
library(lubridate)
library(dplyr)
library(ggridges)
library(learningr)
library(stringr)
```


#Read in data
```{r, message = FALSE, warning = FALSE}
akl_daily_raw           <- read_csv("akl_weather_daily.csv")
akl_hourly_raw          <- read_csv("akl_weather_hourly_2016.csv")
logs                    <- read_csv("cran-logs_2015-04-17.csv")
releases                <- read_csv("rversions.csv")
monarchs <- read_tsv("monarchs.txt") %>% mutate(from = as_datetime(str_pad(from, 10, pad = 0)), to  = as_datetime(str_pad(to, 10, pad = 0)))


```

#Course Description

Dates and times are abundant in data and essential for answering questions that start with when, how long, or how often. However, they can be tricky, as they come in a variety of formats and can behave in unintuitive ways. This course teaches you the essentials of parsing, manipulating, and computing with dates and times in R. By the end, you'll have mastered the lubridate package, a member of the tidyverse, specifically designed to handle dates and times. You'll also have applied your new skills to explore how often R versions are released, when the weather is good in Auckland (the birthplace of R), and how long monarchs ruled in Britain.

#Chapter 1: Dates and Times in R

R doesn't know something is a date or time unless you tell it. In this chapter you'll learn about some of the ways R stores dates and times by exploring how often R versions are released, and how quickly people download them. You'll also get a sneak peek at what you'll learn in the following chapters.

##Specifying dates
As you saw in the video, R doesn't know something is a date unless you tell it. If you have a character string that represents a date in the ISO 8601 standard you can turn it into a Date using the as.Date() function. Just pass the character string (or a vector of character strings) as the first argument.

In this exercise you'll convert a character string representation of a date to a Date object.

INSTRUCTIONS

We've stored the string "2013-04-03" in a variable called x

Use str() to look at the structure of x and confirm it's just a character string.
Convert x to a date using as.Date().
Use str() to look at the structure of x_date and confirm it's a Date.
Now use as.Date() to store the date April 10, 2014.

```{r}
# The date R 3.0.0 was released
x <- "2013-04-03"

# Examine structure of x
str(x)

# Use as.Date() to interpret x as a date
x_date <- as.Date(x)

# Examine structure of x_date
str(x_date)

# Store April 10 2014 as a Date
april_10_2014 <- as.Date("2014-04-10")
```

##Automatic import
Sometimes you'll need to input a couple of dates by hand using as.Date() but it's much more common to have a column of dates in a data file.

Some functions that read in data will automatically recognize and parse dates in a variety of formats. In particular the import functions, like read_csv(), in the readr package will recognize dates in a few common formats.

There is also the anytime() function in the anytime package whose sole goal is to automatically parse strings as dates regardless of the format.

Try them both out in this exercise.

INSTRUCTIONS

Use read_csv() to read in the CSV file rversions.csv as releases.
Use str() to examine the structure of the date column. Notice it's already a Date object.
We've loaded anytime and created an object called sep_10_2009. Use the anytime() function to parse sep_10_2009.

```{r, message = FALSE}
# Load the readr package
library(readr)

# Use read_csv() to import rversions.csv
releases <- read_csv("rversions.csv")

# Examine the structure of the date column
str(releases$date)

# Load the anytime package
library(anytime)

# Various ways of writing Sep 10 2009
sep_10_2009 <- c("September 10 2009", "2009-09-10", "10 Sep 2009", "09-10-2009")

# Use anytime() to parse sep_10_2009
anytime(sep_10_2009)
```

##Plotting

If you plot a Date on the axis of a plot, you expect the dates to be in calendar order, and that's exactly what happens with plot() or ggplot().

In this exercise you'll make some plots with the R version releases data from the previous exercises using ggplot2. There are two big differences when a Date is on an axis:

If you specify limits they must be Date objects.

To control the behavior of the scale you use the scale_x_date() function.

Have a go in this exercise where you explore how often R releases occur.

INSTRUCTIONS

Make a plot of releases over time by setting the x argument of the aes() function to the date column.
Zoom in to the period from 2010 to 2014 by specifying limits from "2010-01-01" to "2014-01-01". Notice these strings need to be wrapped in as.Date() to be interpreted as Date objects.
Adjust the axis labeling by specifying date_breaks of "10 years" and date_labels of "%Y".

```{r}
library(ggplot2)

# Set the x axis to the date column
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major)))

# Limit the axis to between 2010-01-01 and 2014-01-01
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major))) +
  xlim(as.Date("2010-01-01"), as.Date("2014-01-01"))

# Specify breaks every ten years and labels with "%Y"
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major))) +
  scale_x_date(date_breaks = "10 years", date_labels = "%Y")
```


##Arithmetic and logical operators

Since Date objects are internally represented as the number of days since 1970-01-01 you can do basic math and comparisons with dates. You can compare dates with the usual logical operators (<, ==, > etc.), find extremes with min() and max(), and even subtract two dates to find out the time between them.

In this exercise you'll see how these operations work by exploring the last R release. You'll see Sys.date() in the code, it simply returns today's date.

INSTRUCTIONS

Find the date of the most recent release by calling max() on the date column in releases.
Find the rows in releases that have the most recent date, by specifying the comparison date == last_release_date in filter()
Print last_release to see which release this was.
Calculate how long it has been since the most recent release by subtracting last_release_date from Sys.Date().

```{r}
# Find the largest date
last_release_date <- max(releases$date)

# Filter row for last release
last_release <- filter(releases, date == last_release_date)

# Print last_release
last_release

# How long since last release?
Sys.Date() - last_release_date
```


##Getting datetimes into R

Just like dates without times, if you want R to recognize a string as a datetime you need to convert it, although now you use as.POSIXct(). as.POSIXct() expects strings to be in the format YYYY-MM-DD HH:MM:SS.

The only tricky thing is that times will be interpreted in local time based on your machine's set up. You can check your timezone with Sys.timezone(). If you want the time to be interpreted in a different timezone, you just set the tz argument of as.POSIXct(). You'll learn more about time zones in Chapter 4.

In this exercise you'll input a couple of datetimes by hand and then see that read_csv() also handles datetimes automatically in a lot of cases.

INSTRUCTIONS

Use as.POSIXct() and an appropriate string to input the datetime corresponding to Oct 1st 2010 at 12:12:00.
Enter the same datetime again, but now specify the timezone as "America/Los_Angeles".
Use read_csv() to read in rversions.csv again.
Examine the structure of the datetime column to verify read_csv() has correctly interpreted it as a datetime.

```{r, message = FALSE}
# Use as.POSIXct to enter the datetime 
as.POSIXct("2010-10-01 12:12:00")

# Use as.POSIXct again but set the timezone to `"America/Los_Angeles"`
as.POSIXct("2010-10-01 12:12:00", tz = "America/Los_Angeles")

# Use read_csv to import rversions.csv
releases <- read_csv("rversions.csv")

# Examine structure of datetime column
str(releases$datetime)
```

##Datetimes behave nicely too
Just like Date objects, you can plot and do math with POSIXct objects.

As an example, in this exercise you'll see how quickly people download new versions of R, by examining the download logs from the RStudio CRAN mirror.

R 3.2.0 was released at "2015-04-16 07:13:33" so cran-logs_2015-04-17.csv contains a random sample of downloads on the 16th, 17th and 18th.

INSTRUCTIONS

Use read_csv() to import cran-logs_2015-04-17.csv.
Print logs to see the information we have on each download.
Store the R 3.2.0 release time as a POSIXct object.
Find out when the first request for 3.2.0 was made by filtering for values in the datetime column that are greater than release_time.
Finally see how downloads increase by creating histograms of download time for 3.2.0 and the previous version 3.1.3. We've provided most of the code, you just need to specify the x aesthetic to be the datetime column.

```{r, message = FALSE}
# Import "cran-logs_2015-04-17.csv" with read_csv()
logs <- read_csv("cran-logs_2015-04-17.csv")

# Print logs
logs

# Store the release time as a POSIXct object
release_time <- as.POSIXct("2015-04-16 07:13:33", tz = "UTC")

# When is the first download of 3.2.0?
logs %>% 
  filter(datetime > release_time,
    r_version == "3.2.0")

# Examine histograms of downloads by version
ggplot(logs, aes(x = datetime)) +
  geom_histogram() +
  geom_vline(aes(xintercept = as.numeric(release_time)))+
  facet_wrap(~ r_version, ncol = 1)
```


#Chapter 2: Parsing and Manipulating Dates and Times with lubridate

Dates and times come in a huge assortment of formats, so your first hurdle is often to parse the format you have into an R datetime. This chapter teaches you to import dates and times with the lubridate package. You'll also learn how to extract parts of a datetime. You'll practice by exploring the weather in R's birthplace, Auckland NZ.

##Selecting the right parsing function
lubridate provides a set of functions for parsing dates of a known order. For example, ymd() will parse dates with year first, followed by month and then day. The parsing is flexible, for example, it will parse the m whether it is numeric (e.g. 9 or 09), a full month name (e.g. September), or an abbreviated month name (e.g. Sep).

All the functions with y, m and d in any order exist. If your dates have times as well, you can use the functions that start with ymd, dmy, mdy or ydm and are followed by any of _h, _hm or _hms.

To see all the functions available look at ymd() for dates and ymd_hms() for datetimes.

Here are some challenges. In each case we've provided a date, your job is to choose the correct function to parse it.

INSTRUCTIONS

For each date the ISO 8601 format is displayed as a comment after it, to help you check your work

Choose the correct function to parse x.
Choose the correct function to parse y.
Choose the correct function to parse z.


```{r}
library(lubridate)

# Parse x 
x <- "2010 September 20th" # 2010-09-20
ymd(x)

# Parse y 
y <- "02.01.2010"  # 2010-01-02
dmy(y)

# Parse z 
z <- "Sep, 12th 2010 14:00"  # 2010-09-12T14:00
mdy_hm(z)
```


##Specifying an order with `parse_date_time()`
What about if you have something in a really weird order like dym_msh? There's no named function just for that order, but that is where parse_date_time() comes in. parse_date_time() takes an additional argument orders where you can specify the order of the components in the date.

For example, to parse "2010 September 20th" you could say parse_date_time("2010 September 20th", orders = "ymd") and that would be equivalent to using the ymd() function from the previous exercise.

One advantage of parse_date_time() is that you can use more format characters. For example, you can specify weekday names with a, I for 12 hour time, am/pm indicators with p and many others. You can see a whole list on the help page ?parse_date_time.

Another big advantage is that you can specify a vector of orders, and that allows parsing of dates where multiple formats might be used.

You'll try it out in this exercise.

INSTRUCTIONS

x is a trickier datetime. Use the clues in the instructions to parse x.
two_orders has two different orders, parse both by specifying the order to be c("mdy", "dmy").
Parse short_dates with orders = c("dOmY", "OmY", "Y"). What happens to the dates that don't have months or days specified?


```{r}
# Specify an order string to parse x
x <- "Monday June 1st 2010 at 4pm"
parse_date_time(x, orders = "amdyIp")

# Specify order to include both "mdy" and "dmy"
two_orders <- c("October 7, 2001", "October 13, 2002", "April 13, 2003", 
  "17 April 2005", "23 April 2017")
parse_date_time(two_orders, orders = c("mdy", "dmy"))

# Specify order to include "dOmY", "OmY" and "Y"
short_dates <- c("11 December 1282", "May 1372", "1253")
parse_date_time(short_dates, orders = c("dOmY", "OmY", "Y"))

```

##Import daily weather data
In practice you won't be parsing isolated dates and times, they'll be part of a larger dataset. Throughout the chapter after you've mastered a skill with a simpler example (the release times of R for example), you'll practice your lubridate skills in context by working with weather data from Auckland NZ.

There are two data sets: akl_weather_daily.csv a set of once daily summaries for 10 years, and akl_weather_hourly_2016.csv observations every half hour for 2016. You'll import the daily data in this exercise and the hourly weather in the next exercise.

You'll be using functions from dplyr, so if you are feeling rusty, you might want to review filter(), select() and mutate().

INSTRUCTIONS

Import the daily data, "akl_weather_daily.csv" with read_csv().
Print akl_daily_raw to confirm the date column hasn't been interpreted as a date. Can you see why?
Using mutate() overwrite the column date with a parsed version of date. You need to specify the parsing function. Hint: the first date should be September 1.
Print akl_daily to verify the date column is now a Date.
Take a look at the data by plotting date on the x-axis and max_temp of the y-axis.

```{r, message = FALSE}
library(lubridate)
library(readr)
library(dplyr)
library(ggplot2)

# Import CSV with read_csv()
akl_daily_raw <- read_csv("akl_weather_daily.csv")

# Print akl_daily_raw
akl_daily_raw

# Parse date 
akl_daily <- akl_daily_raw %>%
  mutate(date = ymd(date))

# Print akl_daily
akl_daily

# Plot to check work
ggplot(akl_daily, aes(x = date, y = max_temp)) +
  geom_line() 
```


##Import hourly weather data

The hourly data is a little different. The date information is spread over three columns year, month and mday, so you'll need to use make_date() to combine them.

Then the time information is in a separate column again, time. It's quite common to find date and time split across different variables. One way to construct the datetimes is to paste the date and time together and then parse them. You'll do that in this exercise.

INSTRUCTIONS

Import the hourly data, "akl_weather_hourly_2016.csv" with read_csv(), then print akl_hourly_raw to confirm the date is spread over year, month and mday.
Using mutate() create the column date with using make_date().
We've pasted together the date and time columns. Create datetime by parsing the datetime_string column.
Take a look at the date, time and datetime columns to verify they match up.
Take a look at the data by plotting datetime on the x-axis and temperature of the y-axis.

```{r, message = FALSE}
library(lubridate)
library(readr)
library(dplyr)
library(ggplot2)

# Import "akl_weather_hourly_2016.csv"
akl_hourly_raw <- read_csv("akl_weather_hourly_2016.csv")

# Print akl_hourly_raw
akl_hourly_raw

# Use make_date() to combine year, month and mday 
akl_hourly  <- akl_hourly_raw  %>% 
  mutate(date = make_date(year = year, month = month, day = mday))

# Parse datetime_string 
akl_hourly <- akl_hourly  %>% 
  mutate(
    datetime_string = paste(date, time, sep = "T"),
    datetime = ymd_hms(datetime_string)
  )

# Print date, time and datetime columns of akl_hourly
akl_hourly %>% select(date, time, datetime)

# Plot to check work
ggplot(akl_hourly, aes(x = datetime, y = temperature)) +
  geom_line()

```



##What can you extract?
As you saw in the video, components of a datetime can be extracted by lubridate functions with the same name like year(), month(), day(), hour(), minute() and second(). They all work the same way just pass in a datetime or vector of datetimes.

There are also a few useful functions that return other aspects of a datetime like if it occurs in the morning am(), during daylight savings dst(), in a leap_year(), or which quarter() or semester() it occurs in.

Try them out by exploring the release times of R versions using the data from Chapter 1.

INSTRUCTIONS

We've put release_time, the datetime column of the releases dataset from Chapter 1, in your workspace.

Examine the head() of release_time to verify this is a vector of datetimes.
Extract the month from release_time and examine the first few with head().
To see which months have most releases, extract the month then pipe to table().
Repeat, to see which years have the most releases.
Do releases happen in the morning (UTC)? Find out if the hour of a release is less than 12 and summarise with mean().
Alternatively use am() to find out how often releases happen in the morning.

```{r}
release_time <- (releases$datetime)

# Examine the head() of release_time
head(release_time)

# Examine the head() of the months of release_time
head(month(release_time))

# Extract the month of releases 
month(release_time) %>% table()

# Extract the year of releases
year(release_time) %>% table()

# How often is the hour before 12 (noon)?
mean(hour(release_time) < 12)

# How often is the release in am?
mean(am(release_time))

```

##Adding useful labels

In the previous exercise you found the month of releases:

```
head(month(release_time))
```

and received numeric months in return. Sometimes it's nicer (especially for plotting or tables) to have named months. Both the month() and wday() (day of the week) functions have additional arguments label and abbr to achieve just that. Set label = TRUE to have the output labelled with month (or weekday) names, and abbr = FALSE for those names to be written in full rather than abbreviated.

For example, try running:

```
head(month(release_time, label = TRUE, abbr = FALSE))
```

Practice by examining the popular days of the week for R releases.

```{r}
library(ggplot2)

# Use wday() to tabulate release by day of the week
wday(releases$datetime) %>% table()

# Add label = TRUE to make table more readable
wday(releases$datetime, label = TRUE) %>% table()

# Create column wday to hold labelled week days
releases$wday <- wday(releases$datetime, label = TRUE)

# Plot barchart of weekday by type of release
ggplot(releases, aes(x = wday)) +
  geom_bar() +
  facet_wrap(~ type, ncol = 1, scale = "free_y")
```

##Extracting for plotting

Extracting components from a datetime is particularly useful when exploring data. Earlier in the chapter you imported daily data for weather in Auckland, and created a time series plot of ten years of daily maximum temperature. While that plot gives you a good overview of the whole ten years, it's hard to see the annual pattern.

In this exercise you'll use components of the dates to help explore the pattern of maximum temperature over the year. The first step is to create some new columns to hold the extracted pieces, then you'll use them in a couple of plots.

INSTRUCTIONS

Use mutate() to create three new columns: year, yday and month that respectively hold the same components of the date column. Don't forget to label the months with their names.
Create a plot of yday on the x-axis, max_temp of the y-axis where lines are grouped by year. Each year is a line on this plot, with the x-axis running from Jan 1 to Dec 31.
To take an alternate look, create a ridgeline plot(formerly known as a joyplot) with max_temp on the x-axis, month on the y-axis, using geom_density_ridges() from the ggridges package.


```{r}
library(ggplot2)
library(dplyr)
library(ggridges)

# Add columns for year, yday and month
akl_daily <- akl_daily %>%
  mutate(
    year = year(date),
    yday = yday(date),
    month = month(date, label = TRUE))

# Plot max_temp by yday for all years
ggplot(akl_daily, aes(x = yday, y = max_temp)) +
  geom_line(aes(group = year), alpha = 0.5)

# Examine distribtion of max_temp by month
ggplot(akl_daily, aes(x = max_temp, y = month, height = ..density..)) +
  geom_density_ridges(stat = "density")
  
```


##Extracting for filtering and summarizing
Another reason to extract components is to help with filtering observations or creating summaries. For example, if you are only interested in observations made on weekdays (i.e. not on weekends) you could extract the weekdays then filter out weekends, e.g. wday(date) %in% 2:6.

In the last exercise you saw that January, February and March were great times to visit Auckland for warm temperatures, but will you need a raincoat?

In this exercise you'll find out! You'll use the hourly data to calculate how many days in each month there was any rain during the day.

INSTRUCTIONS

Create new columns for the hour and month of the observation from datetime. Make sure you label the month.
Filter to just daytime observations, where the hour is greater than 8 and less than 22.
Group the observations first by month, then by date, and summarise by using any() on the rainy column. This results in one value per day
Summarise again by summing any_rainy. This results in one value per month

```{r}
# Create new columns hour, month and rainy
akl_hourly <- akl_hourly %>%
  mutate(
    hour = hour(datetime),
    month = month(datetime, label = TRUE),
    rainy = weather == "Precipitation"
  )

# Filter for hours between 8am and 10pm (inclusive)
akl_day <- akl_hourly %>% 
  filter(hour >= 8, hour <= 22)

# Summarise for each date if there is any rain
rainy_days <- akl_day %>% 
  group_by(month, date) %>%
  summarise(
    any_rain = any(rainy)
  )

# Summarise for each month, the number of days with rain
rainy_days %>% 
  summarise(
    days_rainy = sum(any_rain)
  )
```

##Practice rounding
As you saw in the video, round_date() rounds a date to the nearest value, floor_date() rounds down, and ceiling_date() rounds up.

All three take a unit argument which specifies the resolution of rounding. You can specify "second", "minute", "hour", "day", "week", "month", "bimonth", "quarter", "halfyear", or "year". Or, you can specify any multiple of those units, e.g. "5 years", "3 minutes" etc.

Try them out with the release datetime of R 3.4.1.

INSTRUCTIONS

Choose the right function and units to round r_3_4_1 down to the nearest day.
Choose the right function and units to round r_3_4_1 to the nearest 5 minutes.
Choose the right function and units to round r_3_4_1 up to the nearest week.
Find the time elapsed on the day of release at the time of release by subtracting r_3_4_1 rounded down to the day from r_3_4_1.

```{r}
r_3_4_1 <- ymd_hms("2016-05-03 07:13:28 UTC")

# Round down to day
floor_date(r_3_4_1, unit = "day")

# Round to nearest 5 minutes
round_date(r_3_4_1, unit = "5 minutes")

# Round up to week 
ceiling_date(r_3_4_1, unit = "week")

# Subtract r_3_4_1 rounded down to day
r_3_4_1 - floor_date(r_3_4_1, unit = "day")
```

##Rounding with the weather data

When is rounding useful? In a lot of the same situations extracting date components is useful. The advantage of rounding over extracting is that it maintains the context of the unit. For example, extracting the hour gives you the hour the datetime occurred, but you lose the day that hour occurred on (unless you extract that too), on the other hand, rounding to the nearest hour maintains the day, month and year.

As an example you'll explore how many observations per hour there really are in the hourly Auckland weather data.

INSTRUCTIONS

Create a new column called day_hour that is datetime rounded down to the nearest hour.
Use count() on day_hour to count how many observations there are in each hour. What looks like the most common value?
Extend the pipeline, so that after counting, you filter for observations where n is not equal to 2


```{r}
# Create day_hour, datetime rounded down to hour
akl_hourly <- akl_hourly %>%
  mutate(
    day_hour = floor_date(datetime, unit = "hour")
  )

# Count observations per hour  
akl_hourly %>% 
  count(day_hour) 

# Find day_hours with n != 2 
akl_hourly %>% 
  count(day_hour) %>%
  filter(n != 2) %>% 
  arrange(desc(n))
```





#Chapter 3: Arithmetic with Dates and Times
Getting datetimes into R is just the first step. Now that you know how to parse datetimes, you need to learn how to do calculations with them. In this chapter, you'll learn the different ways of representing spans of time with lubridate and how to leverage them to do arithmetic on datetimes. By the end of the chapter, you'll have calculated how long it's been since the first man stepped on the moon, generated sequences of dates to help schedule reminders, calculated when an eclipse occurs, and explored the reigns of monarch's of England (and which ones might have seen Halley's comet!).

##How long has it been?

To get finer control over a difference between datetimes use the base function difftime(). For example instead of time1 - time2, you use difftime(time1, time2).

difftime() takes an argument units which specifies the units for the difference. Your options are "secs", "mins", "hours", "days", or "weeks".

To practice you'll find the time since the first man stepped on the moon. You'll also see the lubridate functions today() and now() which when called with no arguments return the current date and time in your system's timezone.

INSTRUCTIONS

Apollo 11 landed on July 20, 1969. Use difftime() to find the number of days between today() and date_landing.
Neil Armstrong stepped onto the surface at 02:56:15 UTC. Use difftime() to find the number of seconds between now() and moment_step.

```{r}
# The date of landing and moment of step
date_landing <- mdy("July 20, 1969")
moment_step <- mdy_hms("July 20, 1969, 02:56:15", tz = "UTC")

# How many days since the first man on the moon?
difftime(today(), date_landing, units = "days")

# How many seconds since the first man on the moon?
difftime(now(), moment_step, units = "secs")

```


##How many seconds are in a day?
How many seconds are in a day? There are 24 hours in a day, 60 minutes in an hour, and 60 seconds in a minute, so there should be 24*60*60 = 86400 seconds, right?

Not always! In this exercise you'll see a counter example, can you figure out what is going on?

INSTRUCTIONS

We've put code to define three times in your script - midnight on March 11th, March 12th and March 13th in 2017 in the US Pacific timezone.

Find the difference in time between mar_13 and mar_12 in seconds. This should match your intuition.
Now, find the difference in time between mar_12 and mar_11 in seconds. Surprised?

```{r}
# Three dates
mar_11 <- ymd_hms("2017-03-11 12:00:00", 
  tz = "America/Los_Angeles")
mar_12 <- ymd_hms("2017-03-12 12:00:00", 
  tz = "America/Los_Angeles")
mar_13 <- ymd_hms("2017-03-13 12:00:00", 
  tz = "America/Los_Angeles")

# Difference between mar_13 and mar_12 in seconds
difftime(mar_13, mar_12, units = "secs")

# Difference between mar_12 and mar_11 in seconds
difftime(mar_12, mar_11, units = "secs")

```

##Adding or subtracting a time span to a datetime
A common use of time spans is to add or subtract them from a moment in time. For, example to calculate the time one day in the future from mar_11 (from the previous exercises), you could do either of:

```
mar_11 + days(1)
mar_11 + ddays(1)
```

Try them in the console, you get different results! But which one is the right one? It depends on your intent. If you want to account for the fact that time units, in this case days, have different lengths (i.e. due to daylight savings), you want a period days(). If you want the time 86400 seconds in the future you use a duration ddays().

In this exercise you'll add and subtract timespans from dates and datetimes.

INSTRUCTIONS

It's Monday Aug 27th 2018 at 2pm and you want to remind yourself this time next week to send an email. Add a period of one week to mon_2pm.
It's Tuesday Aug 28th 2018 at 9am and you are starting some code that usually takes about 81 hours to run. When will it finish? Add a duration of 81 hours to tue_9am.
What were you doing five years ago? Subtract a period of 5 years from today().
Subtract a duration of 5 years from today(). Will this give a different date?

```{r}
# Add a period of one week to mon_2pm
mon_2pm <- dmy_hm("27 Aug 2018 14:00")
mon_2pm + weeks()

# Add a duration of 81 hours to tue_9am
tue_9am <- dmy_hm("28 Aug 2018 9:00")
tue_9am + dhours(81)

# Subtract a period of five years from today()
today() - years(5)

# Subtract a duration of five years from today()
today() - dyears(5)
```

##Arithmetic with timespans
You can add and subtract timespans to create different length timespans, and even multiply them by numbers. For example, to create a duration of three days and three hours you could do: ddays(3) + dhours(3), or 3*ddays(1) + 3*dhours(1) or even 3*(ddays(1) + dhours(1)).

There was an eclipse over North America on 2017-08-21 at 18:26:40. It's possible to predict the next eclipse with similar geometry by calculating the time and date one Saros in the future. A Saros is a length of time that corresponds to 223 Synodic months, a Synodic month being the period of the Moon's phases, a duration of 29 days, 12 hours, 44 minutes and 3 seconds.

Do just that in this exercise!

INSTRUCTIONS

Create a duration corresponding to one Synodic Month: 29 days, 12 hours, 44 minutes and 3 seconds.
Create a duration corresponding to one Saros by multiplying synodic by 223.
Add saros to eclipse_2017 to predict the next eclipse.

```{r}
# Time of North American Eclipse 2017
eclipse_2017 <- ymd_hms("2017-08-21 18:26:40")

# Duration of 29 days, 12 hours, 44 mins and 3 secs
synodic <- ddays(29) + dhours(12) + dminutes(44) + dseconds(3)

# 223 synodic months
saros <- synodic * 223

# Add saros to eclipse_2017
eclipse_2017 + saros

```


##Generating sequences of datetimes
By combining addition and multiplication with sequences you can generate sequences of datetimes. For example, you can generate a sequence of periods from 1 day up to 10 days with,

```
1:10 * days(1)
```

Then by adding this sequence to a specific datetime, you can construct a sequence of datetimes from 1 day up to 10 days into the future
```
today() + 1:10 * days(1)
```

You had a meeting this morning at 8am and you'd like to have that meeting at the same time and day every two weeks for a year. Generate the meeting times in this exercise.

INSTRUCTIONS

Create today_8am() by adding a period of 8 hours to today()
Create a sequence of periods from one period of two weeks, up to 26 periods of two weeks.
Add every_two_weeks to today_8am.

```{r}
# Add a period of 8 hours to today
today_8am <- today() + hours(8)

# Sequence of two weeks from 1 to 26
every_two_weeks <- 1:26 * weeks(2)

# Create datetime for every two weeks for a year
every_two_weeks + today_8am

```


##The tricky thing about months
What should ymd("2018-01-31") + months(1) return? Should it be 30, 31 or 28 days in the future? Try it. In general lubridate returns the same day of the month in the next month, but since the 31st of February doesn't exist lubridate returns a missing value, NA.

There are alternative addition and subtraction operators: %m+% and %m-% that have different behavior. Rather than returning an NA for a non-existent date, they roll back to the last existing date.

You'll explore their behavior by trying to generate a sequence for the last day in every month this year.

INSTRUCTIONS

We've put jan_31, the date for January 31st this year in your workspace.

Start by creating a sequence of 1 to 12 periods of 1 month.
Add month_seq to jan_31. Notice what happens to any month where the 31st doesn't exist
Now add month_seq to jan_31 using the %m+% operator.
Try subtracting month_seq from jan_31 using the %m-% operator.


```{r}
jan_31 <- as_date("2018-01-31")

# A sequence of 1 to 12 periods of 1 month
month_seq <- 1:12 * months(1)

# Add 1 to 12 months to jan_31
month_seq + jan_31

# Replace + with %m+%
month_seq %m+% jan_31

# Replace + with %m-%
month_seq %m-% jan_31


```


##Examining intervals. Reigns of kings and queens
You can create an interval by using the operator %--% with two datetimes. For example ymd("2001-01-01") %--% ymd("2001-12-31") creates an interval for the year of 2001.

Once you have an interval you can find out certain properties like its start, end and length with int_start(), int_end() and int_length() respectively.

Practice by exploring the reigns of kings and queens of Britain (and its historical dominions).

INSTRUCTIONS

We've put the data monarchs in your workspace.

Print monarchs to take a look at the data
Create a new column called reign that is an interval between from and to.
Create another new column, length, that is the interval length of reign. The rest of the pipeline we've filled in for you, it arranges by decreasing length and selects the name, length and dominion columns.

```{r, error = TRUE}
# Print monarchs
 monarchs

# Create an interval for reign
monarchs <- monarchs %>%
  mutate(reign = from %--% to) 

# Find the length of reign, and arrange
monarchs %>%
  mutate(length = int_length(reign)) %>% 
  arrange(desc(length)) %>%
  select(name, length, dominion)
```

##Comparing intervals and datetimes
A common task with intervals is to ask if a certain time is inside the interval or whether it overlaps with another interval.

The operator %within% tests if the datetime (or interval) on the left hand side is within the interval of the right hand side. For example, if y2001 is the interval covering the year 2001,

```
y2001 <- ymd("2001-01-01") %--% ymd("2001-12-31")
```

Then ymd("2001-03-30") %within% y2001 will return TRUE and ymd("2002-03-30") %within% y2001 will return FALSE.

int_overlaps() performs a similar test, but will return true if two intervals overlap at all.

Practice to find out which monarchs saw Halley's comet around 1066.

INSTRUCTIONS

We've put halleys a data set describing appearances of Halley's comet in your workspace.

Print halleys to examine the date. perihelion_date is the date the Comet is closest to the Sun. start_date and end_date are the range of dates the comet is visible from Earth.
Create a new column, visible, that is an interval from start_date to end_date.
You'll work with one appearance, extract the 14th row of halleys.
Filter monarchs to those where halleys_1066$perihelion_date is within reign.
Filter monarchs to those where halleys_1066$visible overlaps reign.


```{r}

```


#Chapter 4: Problems in practice

You now know most of what you need to tackle data that includes dates and times, but there are a few other problems you might encounter in practice. In this final chapter you'll learn a little more about these problems by returning to some of the earlier data examples and learning how to handle time zones, deal with times when you don't care about dates, parse dates quickly, and output dates and times.



